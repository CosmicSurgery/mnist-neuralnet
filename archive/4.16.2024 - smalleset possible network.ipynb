{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396cefc1-f725-4798-8e0c-72a32c668af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "857ceaef-7d39-4dbe-8882-498e8e7e18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b20a538-0e34-41fb-ae78-f0ee80cf251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "    correct /= size\n",
    "    print(f\"Training Error: \\n Accuracy: {(100*correct):>0.1f}%\")\n",
    "\n",
    "    return correct\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9e710df-aa18-4f1c-a7fd-cc720bb2d085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank you Claude!!\n",
    "\n",
    "def DecimalToBinary(num):\n",
    "    if num == 0:\n",
    "        return torch.tensor([0, 0, 0, 0])\n",
    "    elif num == 1:\n",
    "        return torch.tensor([0, 0, 0, 1])\n",
    "    elif num == 2:\n",
    "        return torch.tensor([0, 0, 1, 0])\n",
    "    elif num == 3:\n",
    "        return torch.tensor([0, 0, 1, 1])\n",
    "    elif num == 4:\n",
    "        return torch.tensor([0, 1, 0, 0])\n",
    "    elif num == 5:\n",
    "        return torch.tensor([0, 1, 0, 1])\n",
    "    elif num == 6:\n",
    "        return torch.tensor([0, 1, 1, 0])\n",
    "    elif num == 7:\n",
    "        return torch.tensor([0, 1, 1, 1])\n",
    "    elif num == 8:\n",
    "        return torch.tensor([1, 0, 0, 0])\n",
    "    elif num == 9:\n",
    "        return torch.tensor([1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbf16ea-b618-4bb0-9965-0e0847b49866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8fa08b8e-84bd-4d76-a971-ca1a4282a379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecimalToBinary(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eade61a-9e60-4d1f-abd0-c5e486a3cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
       "        4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2,\n",
       "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861c3814-03c6-43c2-aeb5-901369b82684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32a66a0a-7ca7-4378-a0b5-10d4a52467e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47555d2-ffc8-4015-ad52-b4332695d587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.372502  [   64/60000]\n",
      "loss: 2.240199  [ 6464/60000]\n",
      "loss: 2.173671  [12864/60000]\n",
      "loss: 1.986791  [19264/60000]\n",
      "loss: 1.956882  [25664/60000]\n",
      "loss: 1.902747  [32064/60000]\n",
      "loss: 1.775721  [38464/60000]\n",
      "loss: 1.827866  [44864/60000]\n",
      "loss: 1.688143  [51264/60000]\n",
      "loss: 1.618635  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 54.8%\n",
      "Test Error: \n",
      " Accuracy: 75.4%, Avg loss: 1.591632 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.629079  [   64/60000]\n",
      "loss: 1.506394  [ 6464/60000]\n",
      "loss: 1.563687  [12864/60000]\n",
      "loss: 1.365137  [19264/60000]\n",
      "loss: 1.391124  [25664/60000]\n",
      "loss: 1.379962  [32064/60000]\n",
      "loss: 1.282315  [38464/60000]\n",
      "loss: 1.434766  [44864/60000]\n",
      "loss: 1.293364  [51264/60000]\n",
      "loss: 1.246456  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 77.0%\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 1.216154 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.267438  [   64/60000]\n",
      "loss: 1.142514  [ 6464/60000]\n",
      "loss: 1.227036  [12864/60000]\n",
      "loss: 1.076298  [19264/60000]\n",
      "loss: 1.093141  [25664/60000]\n",
      "loss: 1.104479  [32064/60000]\n",
      "loss: 1.024652  [38464/60000]\n",
      "loss: 1.210060  [44864/60000]\n",
      "loss: 1.083043  [51264/60000]\n",
      "loss: 1.044982  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 80.2%\n",
      "Test Error: \n",
      " Accuracy: 82.2%, Avg loss: 1.010932 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.066749  [   64/60000]\n",
      "loss: 0.945619  [ 6464/60000]\n",
      "loss: 1.029338  [12864/60000]\n",
      "loss: 0.921532  [19264/60000]\n",
      "loss: 0.920552  [25664/60000]\n",
      "loss: 0.943437  [32064/60000]\n",
      "loss: 0.873476  [38464/60000]\n",
      "loss: 1.068925  [44864/60000]\n",
      "loss: 0.955176  [51264/60000]\n",
      "loss: 0.921513  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 81.9%\n",
      "Test Error: \n",
      " Accuracy: 83.7%, Avg loss: 0.884739 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.940619  [   64/60000]\n",
      "loss: 0.825517  [ 6464/60000]\n",
      "loss: 0.901447  [12864/60000]\n",
      "loss: 0.827160  [19264/60000]\n",
      "loss: 0.809621  [25664/60000]\n",
      "loss: 0.839388  [32064/60000]\n",
      "loss: 0.775220  [38464/60000]\n",
      "loss: 0.972844  [44864/60000]\n",
      "loss: 0.869172  [51264/60000]\n",
      "loss: 0.838297  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.799583 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.853816  [   64/60000]\n",
      "loss: 0.745000  [ 6464/60000]\n",
      "loss: 0.812129  [12864/60000]\n",
      "loss: 0.763865  [19264/60000]\n",
      "loss: 0.732210  [25664/60000]\n",
      "loss: 0.766925  [32064/60000]\n",
      "loss: 0.706293  [38464/60000]\n",
      "loss: 0.903320  [44864/60000]\n",
      "loss: 0.806999  [51264/60000]\n",
      "loss: 0.778367  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 83.8%\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.738107 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.790119  [   64/60000]\n",
      "loss: 0.687154  [ 6464/60000]\n",
      "loss: 0.746115  [12864/60000]\n",
      "loss: 0.718413  [19264/60000]\n",
      "loss: 0.674822  [25664/60000]\n",
      "loss: 0.713598  [32064/60000]\n",
      "loss: 0.655135  [38464/60000]\n",
      "loss: 0.850650  [44864/60000]\n",
      "loss: 0.759646  [51264/60000]\n",
      "loss: 0.733127  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 84.3%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.691475 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.741133  [   64/60000]\n",
      "loss: 0.643412  [ 6464/60000]\n",
      "loss: 0.695206  [12864/60000]\n",
      "loss: 0.684088  [19264/60000]\n",
      "loss: 0.630333  [25664/60000]\n",
      "loss: 0.672698  [32064/60000]\n",
      "loss: 0.615512  [38464/60000]\n",
      "loss: 0.809315  [44864/60000]\n",
      "loss: 0.722151  [51264/60000]\n",
      "loss: 0.697771  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 84.8%\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.654760 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.702098  [   64/60000]\n",
      "loss: 0.609030  [ 6464/60000]\n",
      "loss: 0.654636  [12864/60000]\n",
      "loss: 0.657149  [19264/60000]\n",
      "loss: 0.594660  [25664/60000]\n",
      "loss: 0.640320  [32064/60000]\n",
      "loss: 0.583794  [38464/60000]\n",
      "loss: 0.775959  [44864/60000]\n",
      "loss: 0.691565  [51264/60000]\n",
      "loss: 0.669398  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.625007 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.670121  [   64/60000]\n",
      "loss: 0.581183  [ 6464/60000]\n",
      "loss: 0.621458  [12864/60000]\n",
      "loss: 0.635363  [19264/60000]\n",
      "loss: 0.565300  [25664/60000]\n",
      "loss: 0.614041  [32064/60000]\n",
      "loss: 0.557730  [38464/60000]\n",
      "loss: 0.748432  [44864/60000]\n",
      "loss: 0.666025  [51264/60000]\n",
      "loss: 0.646149  [57664/60000]\n",
      "Training Error: \n",
      " Accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 86.6%, Avg loss: 0.600339 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6476794-b3a5-4ba8-9aff-3d98aaf35778",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sns\u001b[38;5;241m.\u001b[39mlineplot((\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtrain_acc, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtest_acc))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_acc' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot((1-train_acc, 1-test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
