{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0776fd-8a9f-49ac-b723-eedcce7c2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4138c02-2842-4738-ac74-6238bff2d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "def get_data(training_data, test_data):\n",
    "    return (\n",
    "        DataLoader(training_data), #, shuffle=True),\n",
    "        DataLoader(test_data),\n",
    "    )\n",
    "\n",
    "train_dl, valid_dl = get_data(training_data, test_data)\n",
    "train_dataloader = DataLoader(training_data, batch_size=1)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cd17e25-57b1-4db0-ada4-d4588b0d5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,y1 = next(iter(train_dl))\n",
    "x1, y1 =x1.flatten(), y1.squeeze()\n",
    "x1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b0340886-c3f1-4b2d-b32c-3396fe3d3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7e37d7c-bb5b-44b8-b1a3-7ddb20ad2bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_one(dataloader, model, loss_fn, optimizer):\n",
    "    X, y1 = next(iter(dataloader))\n",
    "    X =  X[0][None,:]\n",
    "    y1 = y1[None,:][:,0]\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "becf6625-df14-4cc0-a231-822e2167b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    X, y1 = next(iter(dataloader))\n",
    "    X =  X[0][None,:]\n",
    "    y1 = y1[None,:][:,0]\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df7eb3b2-7611-4342-91cc-907ae0ef9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), torch.Size([]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,y1 = next(iter(train_dl))\n",
    "x1, y1 =x1.flatten(), y1.squeeze()\n",
    "x1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ac3cb609-689e-45cc-8bdf-e3a6c417b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, y1 = next(iter(train_dataloader))\n",
    "# x1 =  x1[0][None,:]\n",
    "# y1 = y1[None,:][:,0]\n",
    "# y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "20955ba6-20e1-4d5d-859c-de18f4ada922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = NeuralNetwork().to(device)\n",
    "torch.save(model.state_dict(), \"tinymodel.pth\")\n",
    "model.load_state_dict(torch.load('tinymodel.pth'))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29eb09e1-49f9-45b4-9146-7635fbf39ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('tinymodel.pth')\n",
    "weights = []\n",
    "weights.append(state_dict['linear_relu_stack.0.weight'].clone())\n",
    "weights.append(state_dict['linear_relu_stack.2.weight'].clone())\n",
    "bias = []\n",
    "bias.append(state_dict['linear_relu_stack.0.bias'].clone())\n",
    "bias.append(state_dict['linear_relu_stack.2.bias'].clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "52891dfc-20b9-4fe1-8204-563237c2d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    X[X<0] = 0\n",
    "    return X\n",
    "\n",
    "def d_relu(l):\n",
    "    d = a[l].clone()\n",
    "    d[a[l] < 0] = 0\n",
    "    d[a[l] > 0] = 1\n",
    "    return d\n",
    "\n",
    "def softmax(x):\n",
    "    return x.exp() / x.exp().sum()\n",
    "\n",
    "def delta_l(y_pred, y, l):\n",
    "    if l == len(weights)-1: # This means it's the last layer... must be a vector\n",
    "        y_ = torch.zeros(len(y_pred))\n",
    "        y_[y] = 1\n",
    "        return (y_pred - y_)[None,:]\n",
    "    else:\n",
    "        return (weights[l+1].T@delta_l(y_pred,y,l+1).T)@d_relu(l)\n",
    "    \n",
    "activations = []\n",
    "activations.append(relu)\n",
    "activations.append(softmax)\n",
    "    \n",
    "def forward(X):\n",
    "    a = [X]\n",
    "    \n",
    "    for w,b,func in zip(weights, bias, activations):\n",
    "        a.append(func(a[-1]@w.T+b))\n",
    "    return a\n",
    "\n",
    "def cross_entropy(y_pred,y):\n",
    "    return -y_pred[y].log()\n",
    "\n",
    "def backward(y_pred,y): # hard-wired backprop...\n",
    "    loss_L = delta_l(y_pred,y1,1)\n",
    "    weights[1] -= lr * (a[1][None,:].T@loss_L).T\n",
    "    bias[1] -= lr * loss_L.squeeze()\n",
    "\n",
    "    loss_l = ((weights[1].T@delta_l(y_pred,y,1).T).T*d_relu(1))\n",
    "\n",
    "    weights[0] -= lr * (a[0][None,:].T@loss_l).T\n",
    "    bias[0] -= loss_l.squeeze()\n",
    "        \n",
    "    loss = cross_entropy(y_pred,y)\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "17d41711-16fd-48f7-97fb-333ecb4721f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn_image as isns\n",
    "isns.imgplot(x1.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a4a9fdb-8ec0-47df-881a-043d772e77ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3997, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "train_one(train_dataloader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "235a0fc9-a871-4bb9-8081-772c21efb748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3997)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = forward(x1)\n",
    "cross_entropy(a[-1],y1)\n",
    "backward(a[-1],y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0427e9b9-0dce-4904-8d67-ddbc7da29fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(not sum(bias[-2] != model.state_dict()['linear_relu_stack.0.bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bf6f0ae4-121f-4d4c-881a-d9a585215d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(not sum(bias[-1] != model.state_dict()['linear_relu_stack.2.bias']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "654f1c65-da47-4a36-a150-dfcedf3108e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(not (weights[-2] != model.state_dict()['linear_relu_stack.0.weight']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fdcb0186-651f-4024-af6e-04628303e856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(not (weights[-1][y1] != model.state_dict()['linear_relu_stack.2.weight'][y1]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eef92a94-0270-4864-b192-592556eb631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights[-1] != model.state_dict()['linear_relu_stack.2.weight']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4785a3b0-a2d3-459f-bddf-344ba6ed65ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,  True,\n",
       "         True,  True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False,  True,  True,  True,\n",
       "         True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False,  True,  True,  True,  True,  True,\n",
       "         True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(weights[-2][y1] != model.state_dict()['linear_relu_stack.0.weight'][y1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8043d2b7-0091-4150-ad11-000633dfea1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.2758e-02, -1.7368e-02,  2.4121e-02, -2.1410e-02,  2.9043e-02,\n",
       "         -1.6695e-02,  5.6500e-03,  4.6751e-03, -8.7601e-04,  2.2244e-02,\n",
       "          3.0333e-02, -2.2299e-02,  2.0030e-02,  9.5424e-03, -6.6552e-04,\n",
       "         -2.4972e-02,  1.0594e-02,  2.5923e-02, -3.0655e-02, -3.2984e-02,\n",
       "         -3.5110e-02,  8.2522e-03, -1.0262e-02, -1.1094e-02,  3.3256e-02,\n",
       "         -9.1095e-03, -2.2680e-02,  3.2125e-03, -1.9602e-02, -1.0464e-02,\n",
       "          1.8865e-02,  8.2426e-03, -2.4508e-02,  3.4001e-02,  2.4163e-02,\n",
       "         -2.4346e-02,  1.5557e-02,  1.4676e-02, -2.5627e-02, -2.5100e-02,\n",
       "         -2.9572e-02,  1.5909e-02,  6.2223e-03,  1.5094e-02, -1.5687e-02,\n",
       "          2.6854e-02,  4.5603e-03, -2.8497e-02, -8.9893e-03,  1.8226e-02,\n",
       "          7.8530e-03, -5.4637e-03, -2.4952e-02, -2.2217e-02,  3.0805e-02,\n",
       "         -2.0458e-02,  2.5309e-02, -1.1954e-02,  3.5698e-04, -3.4778e-02,\n",
       "         -1.1609e-02,  3.0106e-02, -3.2064e-02,  1.7970e-02, -3.0057e-02,\n",
       "          5.2090e-03, -3.2380e-02, -2.8273e-02, -2.8832e-02, -1.2384e-02,\n",
       "          4.8628e-03, -2.6185e-02,  9.0513e-03,  2.1510e-02,  2.9114e-02,\n",
       "          3.1623e-02,  2.3514e-02, -1.0517e-02, -3.2914e-03,  3.1599e-02,\n",
       "          1.7766e-02, -9.4712e-03,  2.6964e-02, -3.1212e-02,  3.0567e-02,\n",
       "          1.9982e-02, -2.6195e-02, -2.9129e-02,  2.7929e-02,  3.5233e-02,\n",
       "          3.1165e-03, -1.3955e-02,  2.0336e-02,  1.6112e-02, -4.4572e-03,\n",
       "          2.8593e-02,  2.3149e-02,  8.9036e-03,  1.8544e-02, -3.3453e-02,\n",
       "         -1.6729e-02,  3.9149e-03,  9.7122e-03, -4.8825e-03,  1.3485e-02,\n",
       "          1.0880e-02, -3.3007e-02,  1.1265e-02, -2.9038e-03, -2.4577e-02,\n",
       "          1.2053e-03, -8.7835e-03, -1.8966e-02, -3.2544e-02,  2.9877e-02,\n",
       "         -2.1689e-02,  4.7968e-03,  2.8611e-02, -4.4994e-03, -2.3408e-02,\n",
       "         -3.4552e-02,  5.9341e-03, -1.7920e-02,  2.6045e-03,  1.1408e-02,\n",
       "         -1.0119e-02,  2.4216e-02, -4.6475e-03, -1.4253e-02, -2.3614e-02,\n",
       "          1.0836e-02, -2.2081e-02,  7.5074e-03, -4.5075e-03,  2.4545e-02,\n",
       "         -1.7509e-02, -1.7594e-02, -4.6155e-03, -2.1814e-02,  1.3616e-02,\n",
       "         -1.3082e-02,  1.4653e-02,  2.0728e-02,  2.0855e-02, -6.5565e-03,\n",
       "          1.9491e-02, -1.8912e-02, -3.5584e-02, -3.3989e-03, -2.5895e-02,\n",
       "         -2.7669e-02,  9.0784e-03,  3.0518e-02, -1.4057e-02, -2.0227e-03,\n",
       "         -2.5877e-02,  6.2249e-03,  1.0164e-02, -5.5061e-03,  2.7169e-02,\n",
       "         -2.8766e-02, -4.8264e-03, -1.9857e-02,  3.1342e-02,  3.0251e-02,\n",
       "          3.5130e-02,  3.2859e-02,  1.4145e-02, -2.7347e-02, -2.4226e-02,\n",
       "          8.5615e-03, -3.1886e-02,  2.2610e-02,  1.5527e-02,  8.5212e-03,\n",
       "         -3.1172e-02,  2.5976e-02, -3.7847e-03, -1.5000e-02,  1.8626e-02,\n",
       "          2.9950e-03, -1.5922e-02,  8.3247e-03, -2.3851e-02,  3.3159e-02,\n",
       "          3.1269e-02,  1.6440e-02,  1.8870e-02, -3.5536e-02, -1.9886e-02,\n",
       "         -3.4393e-02, -1.8623e-02, -2.9610e-02,  2.6288e-02,  1.9268e-02,\n",
       "          2.1033e-02, -1.5855e-02,  2.7221e-02, -5.1607e-03, -9.2532e-03,\n",
       "          1.9230e-02,  2.3651e-02, -2.5669e-02,  3.3994e-02, -3.6369e-03,\n",
       "          9.4778e-03, -3.5596e-02,  3.9416e-03, -1.7710e-02, -2.2397e-02,\n",
       "         -1.4946e-02, -2.0072e-04, -1.0209e-02, -2.2912e-02,  2.5558e-02,\n",
       "          1.0614e-02, -3.3248e-02,  7.4841e-03,  8.7679e-03,  1.3123e-03,\n",
       "          8.6723e-03, -2.9902e-03,  1.5619e-02, -2.5142e-02, -1.5228e-02,\n",
       "          2.6754e-02, -2.2126e-02,  1.7523e-02,  3.3045e-02, -3.2658e-02,\n",
       "         -1.5647e-02,  3.0475e-02, -2.1893e-03,  7.0161e-03,  5.0485e-03,\n",
       "          1.4683e-02, -1.4750e-02,  4.6021e-03,  2.4301e-02, -3.0377e-03,\n",
       "         -3.2800e-02,  1.2312e-02, -9.1174e-03, -7.5346e-03,  1.8626e-02,\n",
       "          6.2591e-03, -2.1605e-02, -1.6481e-02, -5.4289e-03, -8.8238e-03,\n",
       "         -7.5607e-03, -2.4411e-02,  2.5872e-02,  1.8522e-02,  7.0481e-03,\n",
       "          8.0865e-03,  4.1810e-03,  2.6705e-02,  8.0815e-03,  5.4404e-03,\n",
       "         -1.9643e-02,  1.1893e-02, -3.3427e-02,  1.1230e-02, -3.0991e-02,\n",
       "         -1.4809e-02,  1.8853e-02, -2.1272e-02,  2.8432e-02, -1.9754e-02,\n",
       "          3.3828e-02,  1.1008e-02, -1.5477e-02,  2.1781e-02, -3.1628e-02,\n",
       "         -2.2625e-02, -2.2375e-02,  4.7014e-03,  3.5087e-03, -3.0718e-02,\n",
       "          3.4463e-02, -3.4131e-05, -1.9071e-02,  8.5308e-04, -1.5330e-02,\n",
       "          9.8533e-03,  1.2929e-02, -1.0131e-02,  2.0821e-03,  2.1248e-02,\n",
       "         -2.3230e-02, -7.9848e-03, -5.3031e-03, -2.3641e-02,  2.9088e-03,\n",
       "          1.3126e-03, -2.8847e-02,  7.3263e-03,  3.4088e-02,  1.8996e-02,\n",
       "         -1.9373e-02,  3.2692e-02, -2.4550e-02, -1.8159e-02,  1.5753e-02,\n",
       "          2.8412e-02,  3.4082e-02,  3.0747e-02, -1.9666e-02,  8.1724e-03,\n",
       "         -2.2426e-02,  7.8869e-04,  2.9589e-02,  1.7585e-02, -3.2978e-02,\n",
       "         -1.5370e-02, -3.0134e-02,  1.6824e-02, -4.5338e-03, -2.6127e-02,\n",
       "         -1.1447e-02,  1.1694e-02,  3.3061e-03,  3.3511e-02, -4.7416e-04,\n",
       "          1.1234e-02, -1.0819e-02,  4.2617e-03,  1.2794e-03,  3.0678e-02,\n",
       "          1.4965e-02, -2.0353e-02, -3.1734e-02, -3.3980e-02, -1.2970e-02,\n",
       "          4.6166e-03,  3.3599e-02, -3.5091e-03,  1.3964e-02,  1.8151e-02,\n",
       "         -2.7357e-02, -2.9543e-02,  1.3533e-02,  1.6647e-02, -1.6630e-02,\n",
       "          5.5967e-03, -3.4968e-02,  4.4867e-04,  8.7286e-03,  3.0370e-04,\n",
       "         -5.6784e-03,  1.4865e-02, -9.8167e-03,  2.6585e-02, -3.0762e-02,\n",
       "         -2.0411e-02, -2.9815e-02, -3.2300e-02,  2.6477e-02, -8.8383e-03,\n",
       "         -2.8055e-02,  7.4075e-03, -2.7045e-02,  1.8462e-03,  1.6978e-02,\n",
       "         -7.5520e-03,  1.8360e-02,  7.3302e-03, -2.8659e-02,  7.0292e-03,\n",
       "          2.3023e-02, -8.2793e-03,  3.3753e-03,  4.5562e-03,  3.0711e-03,\n",
       "          9.2839e-03, -3.4200e-02,  2.7064e-02,  1.5546e-02,  4.3886e-03,\n",
       "          6.4839e-03, -2.8803e-02, -1.0197e-02, -1.5535e-03,  8.4896e-03,\n",
       "         -1.9591e-02,  3.7894e-03, -1.1084e-02,  2.5996e-02, -3.0656e-02,\n",
       "          3.7333e-03,  2.4196e-02, -2.7739e-02, -1.0236e-03,  1.6503e-02,\n",
       "          1.4412e-02,  4.2000e-03,  1.4437e-02, -2.4896e-02,  2.9746e-02,\n",
       "          7.9655e-04,  2.3086e-02,  7.9007e-03, -3.9731e-03,  1.5298e-02,\n",
       "          3.3893e-02,  3.5197e-02, -3.0097e-02,  2.1317e-03, -2.5672e-02,\n",
       "          2.0805e-02,  2.5639e-02, -2.5078e-02, -2.0641e-03,  2.4714e-02,\n",
       "          2.3618e-02, -2.6852e-02,  2.3980e-02, -6.3228e-03, -3.0374e-02,\n",
       "          7.1143e-03,  1.6638e-02,  2.1419e-02, -2.4283e-02, -2.5867e-02,\n",
       "         -2.3996e-02,  2.0240e-02, -3.1214e-02, -3.0116e-04, -1.0495e-02,\n",
       "          1.5593e-02,  7.0137e-03, -1.8035e-02,  6.2381e-03,  3.2861e-02,\n",
       "          5.8549e-03, -1.7732e-02,  1.1614e-03, -3.2779e-02, -2.2918e-02,\n",
       "         -6.6339e-03, -2.2255e-02,  3.0243e-02,  6.9325e-03,  2.7662e-02,\n",
       "         -8.1325e-03, -4.9670e-03,  9.0088e-03, -1.0619e-02, -1.2174e-02,\n",
       "         -3.5035e-02,  2.6905e-02,  3.2322e-02, -3.5362e-02, -1.1816e-02,\n",
       "         -2.7014e-02, -1.4497e-02,  2.7190e-02,  1.9104e-02, -2.7711e-03,\n",
       "          1.5254e-02,  1.0666e-02,  1.9504e-02, -2.8702e-02,  1.1027e-02,\n",
       "         -3.3859e-02, -2.3522e-02, -1.3334e-02, -3.4796e-03, -3.3704e-02,\n",
       "          8.8883e-04,  5.7020e-03, -1.4174e-02,  1.1584e-02,  3.1208e-02,\n",
       "         -6.1005e-03, -1.9021e-02, -3.1637e-02, -2.6079e-02, -1.9753e-02,\n",
       "         -2.6403e-02, -1.4041e-02,  1.9674e-02,  1.1176e-02,  3.2190e-02,\n",
       "          3.5459e-02, -1.2861e-02, -1.3986e-02,  4.8873e-03, -2.8439e-02,\n",
       "          1.9426e-02, -6.4278e-03, -2.9905e-02, -2.6997e-02, -2.4644e-02,\n",
       "          9.7823e-03,  2.7369e-02,  2.8295e-02, -9.8341e-03, -2.0745e-02,\n",
       "         -1.5851e-02, -2.4397e-02, -9.2079e-03, -3.2255e-02,  1.9089e-02,\n",
       "         -3.3614e-02, -2.2216e-02,  2.3968e-02, -2.6715e-02,  8.5380e-03,\n",
       "          2.6751e-02,  3.5204e-02,  1.8071e-02, -9.5845e-03,  2.0408e-02,\n",
       "         -1.1787e-03, -1.1012e-02,  1.1631e-04,  8.0048e-03,  2.3929e-02,\n",
       "          1.4967e-02,  1.7019e-02,  5.3084e-03, -1.8257e-03,  1.4996e-02,\n",
       "          8.5901e-03, -3.4175e-02,  5.7741e-03, -1.5860e-02, -1.8939e-02,\n",
       "          1.3812e-02,  7.3032e-03,  6.0480e-03, -1.6942e-02,  1.6503e-02,\n",
       "          3.3515e-02,  4.3692e-03,  1.4680e-02, -3.1333e-02,  2.1232e-02,\n",
       "          1.2407e-02,  1.6090e-02,  1.4893e-02, -9.3937e-03, -2.1490e-03,\n",
       "          3.4525e-02,  2.6102e-02, -2.5634e-02,  2.8302e-02,  3.5510e-02,\n",
       "          4.6629e-03, -2.7888e-02,  6.9229e-03, -7.2129e-03,  2.5678e-02,\n",
       "         -3.4314e-02,  9.1394e-03, -4.1889e-04,  2.8115e-03,  2.4568e-02,\n",
       "          6.4517e-04, -2.8753e-02, -2.0833e-02, -1.4300e-02,  3.8089e-03,\n",
       "          1.3782e-02, -6.6663e-03, -1.4096e-02,  1.5672e-02, -3.4725e-02,\n",
       "          2.4953e-02, -4.1672e-03,  2.4821e-02,  2.6952e-02,  3.7809e-03,\n",
       "          1.1263e-02, -2.0235e-02,  2.5561e-02,  2.0893e-02, -5.6092e-03,\n",
       "          1.3921e-02, -2.0005e-03,  2.7903e-02,  1.4702e-02,  2.6037e-02,\n",
       "         -3.2464e-02,  3.4797e-02,  1.3306e-02,  1.7364e-02,  7.9582e-03,\n",
       "          2.3457e-02,  3.3622e-02, -3.0425e-03, -2.9304e-02,  3.2795e-02,\n",
       "         -7.5318e-03, -1.7227e-02,  2.1976e-02,  1.9902e-02,  4.7471e-03,\n",
       "         -2.2762e-03, -6.8665e-03,  3.2712e-02,  2.1733e-02,  2.1258e-02,\n",
       "          2.2774e-02, -1.8691e-02,  7.4570e-03, -3.0896e-02,  2.0749e-02,\n",
       "         -3.5400e-02, -3.5693e-02, -3.5303e-02,  2.2024e-02,  3.7168e-03,\n",
       "          8.1215e-05,  5.6805e-03, -1.3516e-02, -1.0845e-02, -2.4057e-02,\n",
       "         -8.7220e-03, -2.1976e-02,  9.3722e-04,  2.8038e-02, -2.9554e-02,\n",
       "          1.7529e-02, -2.6599e-02, -1.4832e-02,  6.9494e-03,  6.1188e-03,\n",
       "          2.9278e-02, -1.4581e-05, -1.3602e-02, -1.4770e-02,  1.0471e-03,\n",
       "         -2.6780e-02, -2.8002e-02, -1.5281e-02,  9.1744e-04, -2.4119e-02,\n",
       "         -2.0387e-02,  2.5500e-02,  3.3004e-02, -1.1187e-02, -3.0641e-02,\n",
       "         -1.3673e-02,  1.4414e-02,  1.1591e-02, -1.1079e-02, -3.1478e-02,\n",
       "         -1.0770e-02, -8.0199e-03,  2.0532e-02, -1.7744e-02,  2.1400e-02,\n",
       "          4.9211e-03, -6.0037e-03, -3.1829e-02,  3.5260e-02, -6.3685e-03,\n",
       "          2.2471e-02, -1.8474e-02, -3.4780e-02, -2.8468e-02, -1.8303e-02,\n",
       "         -1.1374e-02, -5.0433e-03,  2.9786e-02, -3.2938e-02,  1.7826e-02,\n",
       "          3.0051e-02,  2.2987e-04, -2.2273e-02,  1.1423e-03,  8.4728e-03,\n",
       "          1.5802e-02, -1.0875e-02, -1.2290e-02, -1.6883e-02, -3.4578e-02,\n",
       "          1.2514e-02, -2.7019e-02, -1.7175e-02, -3.6970e-04,  2.7532e-02,\n",
       "          3.1755e-02, -2.5977e-02,  3.0975e-02,  3.1992e-02,  2.8851e-02,\n",
       "          3.1094e-03,  2.8684e-02,  1.7352e-02, -2.5627e-02, -1.8824e-02,\n",
       "          6.7167e-04, -2.5310e-02, -1.1760e-02,  2.8794e-02,  1.6628e-02,\n",
       "          3.1103e-02,  2.7379e-04, -1.8211e-02,  2.3637e-02,  2.6329e-03,\n",
       "          6.0144e-03, -1.5132e-02,  1.4670e-02, -2.6377e-02,  2.8499e-02,\n",
       "          3.1244e-02,  1.2887e-02,  2.7812e-02,  2.1677e-02, -1.3640e-02,\n",
       "         -3.0976e-02,  4.6996e-03,  2.2424e-02, -3.6536e-03,  3.0050e-03,\n",
       "          2.6471e-02,  1.4746e-02,  2.6700e-02,  5.2442e-03,  4.0034e-03,\n",
       "         -8.5428e-03, -6.0267e-03, -1.8981e-02,  2.3878e-02,  3.2573e-02,\n",
       "          1.3254e-02,  1.0148e-03, -1.1789e-02, -3.5262e-02, -6.6131e-03,\n",
       "         -2.5354e-02, -2.6367e-02, -7.0720e-03, -7.0257e-03,  7.2045e-03,\n",
       "         -2.5886e-02,  2.5666e-02, -3.2516e-02, -1.6914e-02, -1.3559e-02,\n",
       "          2.2019e-03,  1.4764e-02, -9.4119e-03,  5.5739e-03, -8.4548e-03,\n",
       "         -1.4047e-02, -4.9956e-03,  7.1908e-03, -3.4691e-02, -2.4859e-02,\n",
       "          2.7902e-02,  1.6149e-02, -9.5491e-04,  1.1279e-03,  4.9298e-03,\n",
       "          8.3008e-03, -2.4384e-02, -9.7353e-03, -3.2778e-02, -2.8078e-02,\n",
       "         -6.7198e-03, -4.7156e-03,  2.7934e-02,  6.1516e-03, -5.7909e-03,\n",
       "         -9.8944e-04,  1.9946e-02, -1.0819e-02, -6.6766e-03, -7.1645e-03,\n",
       "         -2.8799e-02, -4.9915e-03, -3.3016e-02, -1.9197e-02, -2.2733e-02,\n",
       "          2.6604e-02, -3.2899e-02,  3.4412e-02,  1.3391e-02]),\n",
       " tensor([-3.2758e-02, -1.7368e-02,  2.4121e-02, -2.1410e-02,  2.9043e-02,\n",
       "         -1.6695e-02,  5.6500e-03,  4.6751e-03, -8.7601e-04,  2.2244e-02,\n",
       "          3.0333e-02, -2.2299e-02,  2.0030e-02,  9.5424e-03, -6.6552e-04,\n",
       "         -2.4972e-02,  1.0594e-02,  2.5923e-02, -3.0655e-02, -3.2984e-02,\n",
       "         -3.5110e-02,  8.2522e-03, -1.0262e-02, -1.1094e-02,  3.3256e-02,\n",
       "         -9.1095e-03, -2.2680e-02,  3.2125e-03, -1.9602e-02, -1.0464e-02,\n",
       "          1.8865e-02,  8.2426e-03, -2.4508e-02,  3.4001e-02,  2.4163e-02,\n",
       "         -2.4346e-02,  1.5557e-02,  1.4676e-02, -2.5627e-02, -2.5100e-02,\n",
       "         -2.9572e-02,  1.5909e-02,  6.2223e-03,  1.5094e-02, -1.5687e-02,\n",
       "          2.6854e-02,  4.5603e-03, -2.8497e-02, -8.9893e-03,  1.8226e-02,\n",
       "          7.8530e-03, -5.4637e-03, -2.4952e-02, -2.2217e-02,  3.0805e-02,\n",
       "         -2.0458e-02,  2.5309e-02, -1.1954e-02,  3.5698e-04, -3.4778e-02,\n",
       "         -1.1609e-02,  3.0106e-02, -3.2064e-02,  1.7970e-02, -3.0057e-02,\n",
       "          5.2090e-03, -3.2380e-02, -2.8273e-02, -2.8832e-02, -1.2384e-02,\n",
       "          4.8628e-03, -2.6185e-02,  9.0513e-03,  2.1510e-02,  2.9114e-02,\n",
       "          3.1623e-02,  2.3514e-02, -1.0517e-02, -3.2914e-03,  3.1599e-02,\n",
       "          1.7766e-02, -9.4712e-03,  2.6964e-02, -3.1212e-02,  3.0567e-02,\n",
       "          1.9982e-02, -2.6195e-02, -2.9129e-02,  2.7929e-02,  3.5233e-02,\n",
       "          3.1165e-03, -1.3955e-02,  2.0336e-02,  1.6112e-02, -4.4572e-03,\n",
       "          2.8593e-02,  2.3149e-02,  8.9036e-03,  1.8544e-02, -3.3453e-02,\n",
       "         -1.6729e-02,  3.9149e-03,  9.7122e-03, -4.8825e-03,  1.3485e-02,\n",
       "          1.0880e-02, -3.3007e-02,  1.1265e-02, -2.9038e-03, -2.4577e-02,\n",
       "          1.2053e-03, -8.7835e-03, -1.8966e-02, -3.2544e-02,  2.9877e-02,\n",
       "         -2.1689e-02,  4.7968e-03,  2.8611e-02, -4.4994e-03, -2.3408e-02,\n",
       "         -3.4552e-02,  5.9341e-03, -1.7920e-02,  2.6045e-03,  1.1408e-02,\n",
       "         -1.0119e-02,  2.4216e-02, -4.6475e-03, -1.4253e-02, -2.3614e-02,\n",
       "          1.0836e-02, -2.2081e-02,  7.5074e-03, -4.5075e-03,  2.4545e-02,\n",
       "         -1.7509e-02, -1.7594e-02, -4.6155e-03, -2.1814e-02,  1.3616e-02,\n",
       "         -1.3082e-02,  1.4653e-02,  2.0728e-02,  2.0855e-02, -6.5565e-03,\n",
       "          1.9491e-02, -1.8912e-02, -3.5584e-02, -3.3989e-03, -2.5895e-02,\n",
       "         -2.7669e-02,  9.0784e-03,  3.0519e-02, -1.4055e-02, -2.0203e-03,\n",
       "         -2.5875e-02,  6.2420e-03,  1.0182e-02, -5.4823e-03,  2.7172e-02,\n",
       "         -2.8744e-02, -4.7917e-03, -1.9824e-02,  3.1359e-02,  3.0251e-02,\n",
       "          3.5130e-02,  3.2859e-02,  1.4145e-02, -2.7347e-02, -2.4226e-02,\n",
       "          8.5615e-03, -3.1886e-02,  2.2610e-02,  1.5527e-02,  8.5212e-03,\n",
       "         -3.1172e-02,  2.5980e-02, -3.7798e-03, -1.4987e-02,  1.8647e-02,\n",
       "          3.0181e-03, -1.5887e-02,  8.3590e-03, -2.3816e-02,  3.3193e-02,\n",
       "          3.1303e-02,  1.6471e-02,  1.8894e-02, -3.5502e-02, -1.9853e-02,\n",
       "         -3.4367e-02, -1.8614e-02, -2.9610e-02,  2.6288e-02,  1.9268e-02,\n",
       "          2.1033e-02, -1.5855e-02,  2.7221e-02, -5.1607e-03, -9.2532e-03,\n",
       "          1.9230e-02,  2.3651e-02, -2.5669e-02,  3.4001e-02, -3.6046e-03,\n",
       "          9.5121e-03, -3.5562e-02,  3.9759e-03, -1.7676e-02, -2.2362e-02,\n",
       "         -1.4912e-02, -1.6636e-04, -1.0174e-02, -2.2878e-02,  2.5571e-02,\n",
       "          1.0625e-02, -3.3237e-02,  7.4917e-03,  8.7732e-03,  1.3123e-03,\n",
       "          8.6723e-03, -2.9902e-03,  1.5619e-02, -2.5142e-02, -1.5228e-02,\n",
       "          2.6754e-02, -2.2126e-02,  1.7523e-02,  3.3045e-02, -3.2658e-02,\n",
       "         -1.5647e-02,  3.0478e-02, -2.1595e-03,  7.0505e-03,  5.0828e-03,\n",
       "          1.4718e-02, -1.4715e-02,  4.6365e-03,  2.4328e-02, -3.0130e-03,\n",
       "         -3.2766e-02,  1.2345e-02, -9.1174e-03, -7.5346e-03,  1.8626e-02,\n",
       "          6.2591e-03, -2.1605e-02, -1.6481e-02, -5.4289e-03, -8.8238e-03,\n",
       "         -7.5607e-03, -2.4411e-02,  2.5872e-02,  1.8522e-02,  7.0481e-03,\n",
       "          8.0865e-03,  4.1810e-03,  2.6705e-02,  8.0815e-03,  5.4404e-03,\n",
       "         -1.9633e-02,  1.1914e-02, -3.3412e-02,  1.1264e-02, -3.0957e-02,\n",
       "         -1.4781e-02,  1.8855e-02, -2.1272e-02,  2.8438e-02, -1.9733e-02,\n",
       "          3.3828e-02,  1.1008e-02, -1.5477e-02,  2.1781e-02, -3.1628e-02,\n",
       "         -2.2625e-02, -2.2375e-02,  4.7014e-03,  3.5087e-03, -3.0718e-02,\n",
       "          3.4463e-02, -3.4131e-05, -1.9071e-02,  8.5308e-04, -1.5330e-02,\n",
       "          9.8533e-03,  1.2929e-02, -1.0131e-02,  2.0821e-03,  2.1250e-02,\n",
       "         -2.3230e-02, -7.9639e-03, -5.2687e-03, -2.3629e-02,  2.9088e-03,\n",
       "          1.3126e-03, -2.8847e-02,  7.3263e-03,  3.4088e-02,  1.8996e-02,\n",
       "         -1.9373e-02,  3.2692e-02, -2.4550e-02, -1.8159e-02,  1.5753e-02,\n",
       "          2.8412e-02,  3.4082e-02,  3.0747e-02, -1.9666e-02,  8.1724e-03,\n",
       "         -2.2426e-02,  7.8869e-04,  2.9589e-02,  1.7585e-02, -3.2978e-02,\n",
       "         -1.5370e-02, -3.0134e-02,  1.6824e-02, -4.5338e-03, -2.6108e-02,\n",
       "         -1.1412e-02,  1.1720e-02,  3.3064e-03,  3.3511e-02, -4.7416e-04,\n",
       "          1.1234e-02, -1.0819e-02,  4.2617e-03,  1.2794e-03,  3.0678e-02,\n",
       "          1.4965e-02, -2.0353e-02, -3.1734e-02, -3.3980e-02, -1.2970e-02,\n",
       "          4.6166e-03,  3.3599e-02, -3.5091e-03,  1.3964e-02,  1.8151e-02,\n",
       "         -2.7357e-02, -2.9543e-02,  1.3533e-02,  1.6647e-02, -1.6630e-02,\n",
       "          5.5967e-03, -3.4968e-02,  4.5017e-04,  8.7544e-03,  3.3806e-04,\n",
       "         -5.6689e-03,  1.4865e-02, -9.8167e-03,  2.6585e-02, -3.0762e-02,\n",
       "         -2.0411e-02, -2.9815e-02, -3.2300e-02,  2.6477e-02, -8.8383e-03,\n",
       "         -2.8055e-02,  7.4075e-03, -2.7045e-02,  1.8462e-03,  1.6978e-02,\n",
       "         -7.5520e-03,  1.8360e-02,  7.3302e-03, -2.8659e-02,  7.0292e-03,\n",
       "          2.3023e-02, -8.2793e-03,  3.3753e-03,  4.5562e-03,  3.0711e-03,\n",
       "          9.2839e-03, -3.4195e-02,  2.7097e-02,  1.5577e-02,  4.4104e-03,\n",
       "          6.4986e-03, -2.8802e-02, -1.0197e-02, -1.5535e-03,  8.4896e-03,\n",
       "         -1.9591e-02,  3.7894e-03, -1.1084e-02,  2.5996e-02, -3.0656e-02,\n",
       "          3.7333e-03,  2.4196e-02, -2.7739e-02, -1.0236e-03,  1.6503e-02,\n",
       "          1.4412e-02,  4.2000e-03,  1.4437e-02, -2.4896e-02,  2.9746e-02,\n",
       "          7.9655e-04,  2.3086e-02,  7.9007e-03, -3.9731e-03,  1.5298e-02,\n",
       "          3.3904e-02,  3.5229e-02, -3.0062e-02,  2.1661e-03, -2.5656e-02,\n",
       "          2.0809e-02,  2.5639e-02, -2.5078e-02, -2.0641e-03,  2.4714e-02,\n",
       "          2.3618e-02, -2.6852e-02,  2.3980e-02, -6.3228e-03, -3.0374e-02,\n",
       "          7.1143e-03,  1.6638e-02,  2.1419e-02, -2.4283e-02, -2.5867e-02,\n",
       "         -2.3996e-02,  2.0240e-02, -3.1214e-02, -3.0116e-04, -1.0495e-02,\n",
       "          1.5593e-02,  7.0137e-03, -1.8035e-02,  6.2381e-03,  3.2867e-02,\n",
       "          5.8801e-03, -1.7698e-02,  1.1957e-03, -3.2759e-02, -2.2914e-02,\n",
       "         -6.6339e-03, -2.2255e-02,  3.0243e-02,  6.9325e-03,  2.7662e-02,\n",
       "         -8.1325e-03, -4.9670e-03,  9.0088e-03, -1.0619e-02, -1.2174e-02,\n",
       "         -3.5035e-02,  2.6905e-02,  3.2322e-02, -3.5362e-02, -1.1816e-02,\n",
       "         -2.7014e-02, -1.4497e-02,  2.7190e-02,  1.9104e-02, -2.7711e-03,\n",
       "          1.5254e-02,  1.0666e-02,  1.9504e-02, -2.8700e-02,  1.1040e-02,\n",
       "         -3.3825e-02, -2.3488e-02, -1.3309e-02, -3.4796e-03, -3.3704e-02,\n",
       "          8.8883e-04,  5.7020e-03, -1.4174e-02,  1.1584e-02,  3.1208e-02,\n",
       "         -6.1005e-03, -1.9021e-02, -3.1637e-02, -2.6079e-02, -1.9753e-02,\n",
       "         -2.6403e-02, -1.4041e-02,  1.9674e-02,  1.1176e-02,  3.2190e-02,\n",
       "          3.5459e-02, -1.2861e-02, -1.3986e-02,  4.8873e-03, -2.8439e-02,\n",
       "          1.9426e-02, -6.4278e-03, -2.9905e-02, -2.6964e-02, -2.4610e-02,\n",
       "          9.8161e-03,  2.7378e-02,  2.8295e-02, -9.8341e-03, -2.0745e-02,\n",
       "         -1.5851e-02, -2.4397e-02, -9.2079e-03, -3.2255e-02,  1.9089e-02,\n",
       "         -3.3614e-02, -2.2216e-02,  2.3968e-02, -2.6715e-02,  8.5380e-03,\n",
       "          2.6751e-02,  3.5204e-02,  1.8071e-02, -9.5845e-03,  2.0408e-02,\n",
       "         -1.1787e-03, -1.1012e-02,  1.1631e-04,  8.0110e-03,  2.3947e-02,\n",
       "          1.4992e-02,  1.7053e-02,  5.3428e-03, -1.7976e-03,  1.4996e-02,\n",
       "          8.5901e-03, -3.4175e-02,  5.7741e-03, -1.5860e-02, -1.8939e-02,\n",
       "          1.3812e-02,  7.3032e-03,  6.0480e-03, -1.6942e-02,  1.6503e-02,\n",
       "          3.3515e-02,  4.3692e-03,  1.4680e-02, -3.1333e-02,  2.1232e-02,\n",
       "          1.2407e-02,  1.6090e-02,  1.4893e-02, -9.3937e-03, -2.1438e-03,\n",
       "          3.4545e-02,  2.6133e-02, -2.5600e-02,  2.8337e-02,  3.5544e-02,\n",
       "          4.6968e-03, -2.7864e-02,  6.9229e-03, -7.2129e-03,  2.5678e-02,\n",
       "         -3.4314e-02,  9.1394e-03, -4.1889e-04,  2.8115e-03,  2.4568e-02,\n",
       "          6.4517e-04, -2.8753e-02, -2.0833e-02, -1.4300e-02,  3.8089e-03,\n",
       "          1.3782e-02, -6.6663e-03, -1.4096e-02,  1.5672e-02, -3.4725e-02,\n",
       "          2.4956e-02, -4.1517e-03,  2.4851e-02,  2.6986e-02,  3.8152e-03,\n",
       "          1.1297e-02, -2.0200e-02,  2.5589e-02,  2.0903e-02, -5.6092e-03,\n",
       "          1.3921e-02, -2.0005e-03,  2.7903e-02,  1.4702e-02,  2.6037e-02,\n",
       "         -3.2464e-02,  3.4797e-02,  1.3306e-02,  1.7364e-02,  7.9582e-03,\n",
       "          2.3457e-02,  3.3622e-02, -3.0425e-03, -2.9304e-02,  3.2795e-02,\n",
       "         -7.5318e-03, -1.7224e-02,  2.1985e-02,  1.9931e-02,  4.7815e-03,\n",
       "         -2.2419e-03, -6.8322e-03,  3.2747e-02,  2.1760e-02,  2.1269e-02,\n",
       "          2.2774e-02, -1.8691e-02,  7.4570e-03, -3.0896e-02,  2.0749e-02,\n",
       "         -3.5400e-02, -3.5693e-02, -3.5303e-02,  2.2024e-02,  3.7168e-03,\n",
       "          8.1215e-05,  5.6805e-03, -1.3516e-02, -1.0845e-02, -2.4057e-02,\n",
       "         -8.7220e-03, -2.1976e-02,  9.3966e-04,  2.8061e-02, -2.9525e-02,\n",
       "          1.7563e-02, -2.6564e-02, -1.4797e-02,  6.9837e-03,  6.1453e-03,\n",
       "          2.9288e-02, -1.3359e-05, -1.3602e-02, -1.4770e-02,  1.0471e-03,\n",
       "         -2.6780e-02, -2.8002e-02, -1.5281e-02,  9.1744e-04, -2.4119e-02,\n",
       "         -2.0387e-02,  2.5500e-02,  3.3004e-02, -1.1187e-02, -3.0641e-02,\n",
       "         -1.3673e-02,  1.4414e-02,  1.1591e-02, -1.1071e-02, -3.1454e-02,\n",
       "         -1.0739e-02, -7.9855e-03,  2.0567e-02, -1.7710e-02,  2.1434e-02,\n",
       "          4.9542e-03, -5.9857e-03, -3.1828e-02,  3.5260e-02, -6.3685e-03,\n",
       "          2.2471e-02, -1.8474e-02, -3.4780e-02, -2.8468e-02, -1.8303e-02,\n",
       "         -1.1374e-02, -5.0433e-03,  2.9786e-02, -3.2938e-02,  1.7826e-02,\n",
       "          3.0051e-02,  2.2987e-04, -2.2273e-02,  1.1423e-03,  8.4728e-03,\n",
       "          1.5802e-02, -1.0856e-02, -1.2256e-02, -1.6849e-02, -3.4543e-02,\n",
       "          1.2543e-02, -2.7001e-02, -1.7157e-02, -3.6753e-04,  2.7532e-02,\n",
       "          3.1755e-02, -2.5977e-02,  3.0975e-02,  3.1992e-02,  2.8851e-02,\n",
       "          3.1094e-03,  2.8684e-02,  1.7352e-02, -2.5627e-02, -1.8824e-02,\n",
       "          6.7167e-04, -2.5310e-02, -1.1760e-02,  2.8794e-02,  1.6628e-02,\n",
       "          3.1103e-02,  2.7379e-04, -1.8211e-02,  2.3637e-02,  2.6329e-03,\n",
       "          6.0144e-03, -1.5132e-02,  1.4670e-02, -2.6377e-02,  2.8499e-02,\n",
       "          3.1244e-02,  1.2887e-02,  2.7812e-02,  2.1677e-02, -1.3640e-02,\n",
       "         -3.0976e-02,  4.6996e-03,  2.2424e-02, -3.6536e-03,  3.0050e-03,\n",
       "          2.6471e-02,  1.4746e-02,  2.6700e-02,  5.2442e-03,  4.0034e-03,\n",
       "         -8.5428e-03, -6.0267e-03, -1.8981e-02,  2.3878e-02,  3.2573e-02,\n",
       "          1.3254e-02,  1.0148e-03, -1.1789e-02, -3.5262e-02, -6.6131e-03,\n",
       "         -2.5354e-02, -2.6367e-02, -7.0720e-03, -7.0257e-03,  7.2045e-03,\n",
       "         -2.5886e-02,  2.5666e-02, -3.2516e-02, -1.6914e-02, -1.3559e-02,\n",
       "          2.2019e-03,  1.4764e-02, -9.4119e-03,  5.5739e-03, -8.4548e-03,\n",
       "         -1.4047e-02, -4.9956e-03,  7.1908e-03, -3.4691e-02, -2.4859e-02,\n",
       "          2.7902e-02,  1.6149e-02, -9.5491e-04,  1.1279e-03,  4.9298e-03,\n",
       "          8.3008e-03, -2.4384e-02, -9.7353e-03, -3.2778e-02, -2.8078e-02,\n",
       "         -6.7198e-03, -4.7156e-03,  2.7934e-02,  6.1516e-03, -5.7909e-03,\n",
       "         -9.8944e-04,  1.9946e-02, -1.0819e-02, -6.6766e-03, -7.1645e-03,\n",
       "         -2.8799e-02, -4.9915e-03, -3.3016e-02, -1.9197e-02, -2.2733e-02,\n",
       "          2.6604e-02, -3.2899e-02,  3.4412e-02,  1.3391e-02]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[-2][y1], model.state_dict()['linear_relu_stack.0.weight'][y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a57b5b5-019c-4dd0-a462-ca63644748e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
