{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9eb690-1ece-4c35-bf72-1350cd9bd3d0",
   "metadata": {},
   "source": [
    "# This is the master notebook where I can:\n",
    "- [ ] Generate log files\n",
    "    - [ ] Initiailze network parameters\n",
    "        - [ ] .bin files for validation on hardware\n",
    "        - [ ] .mif files (hex for simulation, text for decimal values)\n",
    "    - [ ] Run network\n",
    "        - [ ] run fixed point check -> output in binary, hex and decimal?\n",
    "        - [ ] run pytorch check? -> output in decimal\n",
    "        - [ ] Generate log file with python script and c program timing -> most important?, single forward pass, and time for one pass through an epoch without training\n",
    "    - [ ] Compare python script and c program accuracy with fixed-point accuracy -> compares data from output files\n",
    "        - [ ]  Generate log file with the results.\n",
    "- Directory structure?\n",
    "    - Notebook with variou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8818574c-2066-4d09-bd72-afde5ee5804f",
   "metadata": {},
   "source": [
    "# Directory Structure\n",
    "- Scripts\n",
    "    - img\n",
    "        - MNIST_train.txt\n",
    "        - MNIST_test.txt\n",
    "        - MNIST_train.bin\n",
    "        - MNIST_test.bin\n",
    "    - runs\n",
    "        - 11.11.2024 -x32-10-10\n",
    "            - Init parameters and expected output?\n",
    "                * binary_files\n",
    "                * mif files (hex?)\n",
    "                * txt files (Decimal?)\n",
    "            - Results\n",
    "                * binary outputs (final parameters in binary?)\n",
    "                * text outputs (performance? Training results?)\n",
    "                * \n",
    "    - PLNN_master.ipynb\n",
    "    - Initialize network run.py -> generates a run for the current date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c3c79c-c7f8-4e50-b25d-2d7b9fdf377e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Design Initialization script\n",
    "#### this script randomly generates the initiailization weights and biases, and stores them in the relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb9d3a9-6943-4f0e-b853-470dd4326970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fxpmath import Fxp\n",
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from fxpmath import Fxp\n",
    "\n",
    "DEBUG_MODE = True\n",
    "INPUT_SIZE = 784\n",
    "\n",
    "network_parameters = [10,10]\n",
    "\n",
    "runs_folder = \"runs\"\n",
    "now = datetime.now()\n",
    "date = '.'.join([str(k) for k in [now.month, now.day, now.year]])\n",
    "run_name = '-'.join((date, '.'.join([str(k) for k in network_parameters])))\n",
    "run_name = 'test'\n",
    "run_path = \"\\\\\".join((runs_folder, run_name))\n",
    "\n",
    "\n",
    "bin_folder = \"\\\\\".join((run_path,\"bin_files\")) # should include a file for expected outputs as a lits of output values for all layers concatenated\n",
    "mif_folder = \"\\\\\".join((run_path,\"mif_files\")) # hex files for simulation go here including expected values\n",
    "txt_folder = \"\\\\\".join((run_path,\"txt_files\")) # same as the above but in decimal representation\n",
    "folders = [bin_folder, mif_folder, txt_folder]\n",
    "\n",
    "x32 = Fxp(-7.25, dtype='S5.27') # For now hardwired to 32/64 bits, but could be made to be generalizable\n",
    "x64 = Fxp(-7.25, dtype='S10.54')\n",
    "weights = []\n",
    "bias = []\n",
    "\n",
    "\n",
    "if os.path.isdir(run_path) and not DEBUG_MODE:\n",
    "    raise ValueError(f\"The directory \\\"{\"\\\\\".join((runs_folder, run_name))}\\\", already exists!\")\n",
    "\n",
    "os.makedirs(run_path,exist_ok=True)\n",
    "for folder in folders:\n",
    "    os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "# This is where I should start generating random weights and biases and save them to the various folders\n",
    "\n",
    "for layer in range(len(network_parameters)):\n",
    "    \n",
    "    input_size_for_layer = INPUT_SIZE if layer == 0 else network_parameters[layer - 1]\n",
    "    weights.append((np.random.rand(input_size_for_layer, network_parameters[layer]) * 2) - 1) # This generates uniformly random weights within range {-1, 1}\n",
    "    bias.append((np.random.rand(network_parameters[layer]) * 2) - 1) # This generates uniformly random biases within range {-1, 1}\n",
    "\n",
    "    with open(os.path.join(mif_folder, f\"bias_{layer}.mif\"), \"w\") as file:\n",
    "        for i in range(network_parameters[layer]):\n",
    "            file.write(str(x32(bias[layer][i]).hex()) + \"\\n\")\n",
    "        \n",
    "    with open(os.path.join(txt_folder, f\"bias_{layer}.txt\"), \"w\") as file:\n",
    "        for i in range(network_parameters[layer]):\n",
    "            file.write(str(float(x32(bias[layer][i]))) + \"\\n\")\n",
    "            \n",
    "    with open(os.path.join(bin_folder, f\"bias_{layer}.bin\"), \"wb\") as file:\n",
    "        for i in range(network_parameters[layer]):\n",
    "            file.write(struct.pack('<I', int(x32(bias[layer][i]).hex(),0)))\n",
    "\n",
    "    for neuron in range(network_parameters[layer]):\n",
    "                \n",
    "        with open(os.path.join(mif_folder, f\"weight_{layer}_{neuron}.mif\"), \"w\") as file:\n",
    "            for i in range(input_size_for_layer):\n",
    "                file.write(str(x32(weights[layer][i, neuron]).hex()) + \"\\n\")\n",
    "            \n",
    "        with open(os.path.join(txt_folder, f\"weight_{layer}_{neuron}.txt\"), \"w\") as file:\n",
    "            for i in range(input_size_for_layer):\n",
    "                file.write(str(float(x32(weights[layer][i, neuron]))) + \"\\n\")\n",
    "                \n",
    "        with open(os.path.join(bin_folder, f\"weight_{layer}_{neuron}.bin\"), \"wb\") as file:\n",
    "            for i in range(input_size_for_layer):\n",
    "                file.write(struct.pack('<I', int(x32(weights[layer][i, neuron]).hex(),0)))\n",
    "\n",
    "\n",
    "# That should be it for initialization, I can have a seperate script handle the expected results -> start with expected fixed-point values? -> write to the same folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4eb453-13f2-439c-9e8a-48fe29b39b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run init_design.py [10,10] True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce29dda2-ea29-45f3-8714-1920146ed66a",
   "metadata": {},
   "source": [
    "### Fixed-point network simulator\n",
    "#### Accepts as a parameter the run name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8099d6e2-11dd-4dc0-be0c-86f40ae8cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you Chatgpt!!!\n",
    "def twos_complement(bin_str):\n",
    "    \"\"\"Returns the two's complement of a binary string.\"\"\"\n",
    "    # Invert the bits\n",
    "    inverted = ''.join('1' if bit == '0' else '0' for bit in bin_str)\n",
    "    # Add 1 to the inverted binary string\n",
    "    carry = 1\n",
    "    result = list(inverted)\n",
    "    \n",
    "    for i in range(len(inverted) - 1, -1, -1):\n",
    "        if result[i] == '1' and carry == 1:\n",
    "            result[i] = '0'\n",
    "        elif result[i] == '0' and carry == 1:\n",
    "            result[i] = '1'\n",
    "            carry = 0\n",
    "        # No carry to add; break early\n",
    "        if carry == 0:\n",
    "            break\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "def add_binary(bin_str1, bin_str2):\n",
    "    \"\"\"Adds two binary strings and returns the result as a binary string, \n",
    "    handling overflow by setting the result to the max/min value depending on overflow direction.\"\"\"\n",
    "    max_len = max(len(bin_str1), len(bin_str2))\n",
    "    bin_str1 = bin_str1.zfill(max_len)\n",
    "    bin_str2 = bin_str2.zfill(max_len)\n",
    "    \n",
    "    carry = 0\n",
    "    result = []\n",
    "    \n",
    "    # Perform bitwise addition from LSB to MSB\n",
    "    for i in range(max_len - 1, -1, -1):\n",
    "        bit_sum = carry + int(bin_str1[i]) + int(bin_str2[i])\n",
    "        result.append(str(bit_sum % 2))\n",
    "        carry = bit_sum // 2\n",
    "    \n",
    "    result = ''.join(result[::-1])  # Reverse the result to get the correct order\n",
    "    \n",
    "    # Check for overflow\n",
    "    sign1 = bin_str1[0]  # Sign bit of the first number\n",
    "    sign2 = bin_str2[0]  # Sign bit of the second number\n",
    "    result_sign = result[0]  # Sign bit of the result\n",
    "\n",
    "    # Overflow occurs if both numbers have the same sign but the result has a different sign\n",
    "    if sign1 == sign2 and sign1 != result_sign:\n",
    "        if sign1 == '0':  # Positive overflow\n",
    "            result = '0' + '1' * (max_len - 1)  # Max positive value: 011...111\n",
    "            # return 'fail'\n",
    "            raise Exception(f\"OVERFLOW\")\n",
    "        else:  # Negative overflow\n",
    "            result = '1' + '0' * (max_len - 1)  # Max negative value: 100...000\n",
    "            raise Exception(f\"OVERFLOW\")\n",
    "            \n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def manual_binary_multiply(bin_str1, bin_str2):\n",
    "    \"\"\"Multiplies two binary strings in two's complement format manually.\"\"\"\n",
    "    # Check for sign and convert to positive if necessary\n",
    "    is_negative1 = bin_str1[0] == '1'\n",
    "    is_negative2 = bin_str2[0] == '1'\n",
    "    \n",
    "    if is_negative1:\n",
    "        bin_str1 = twos_complement(bin_str1)\n",
    "    if is_negative2:\n",
    "        bin_str2 = twos_complement(bin_str2)\n",
    "\n",
    "    # Perform binary multiplication (manual)\n",
    "    len1 = len(bin_str1)\n",
    "    len2 = len(bin_str2)\n",
    "    result = '0' * (len1 + len2)\n",
    "    \n",
    "    for i in range(len2 - 1, -1, -1):\n",
    "        if bin_str2[i] == '1':\n",
    "            # Shift bin_str1 by (len2 - 1 - i) and add to the result\n",
    "            shifted_bin_str1 = bin_str1 + '0' * (len2 - 1 - i)\n",
    "            result = add_binary(result, shifted_bin_str1.zfill(len1 + len2))\n",
    "    \n",
    "    # Determine the sign of the result\n",
    "    if is_negative1 != is_negative2:\n",
    "        result = twos_complement(result.zfill(len1 + len2))\n",
    "\n",
    "    # Truncate the result to the appropriate length (len1 + len2 bits)\n",
    "    return result[-(len1 + len2):]\n",
    "\n",
    "\n",
    "def convert32_64(bin_str1):\n",
    "    bin_str2 = ['0']*64\n",
    "    if bin_str1[0] == '1': # this means the number is negative\n",
    "        bin_str2[:5] = '1'*5\n",
    "        \n",
    "    bin_str2[5:len(bin_str1)+5] = bin_str1\n",
    "    bin_str2 = ''.join(bin_str2)\n",
    "        \n",
    "    return bin_str2\n",
    "\n",
    "def convert64_32(bin_str1):\n",
    "    if bin_str1[0] == '1':\n",
    "        if bin_str1[1:5] != '1111':\n",
    "            print(bin_str1)\n",
    "            raise Exception(f\"OVERFLOW\")\n",
    "        else:\n",
    "            bin_str2 = '0'*32\n",
    "    else:\n",
    "        if bin_str1[1:5] != '0000':\n",
    "            print(bin_str1)\n",
    "            raise Exception(f\"OVERFLOW\")\n",
    "        else:\n",
    "            bin_str2 = bin_str1[5:32+5]\n",
    "        \n",
    "    return bin_str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "133633a9-d538-4834-8869-588f7d62e87a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fxpmath import Fxp\n",
    "import sys\n",
    "import os\n",
    "import struct\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from fxpmath import Fxp\n",
    "\n",
    "# script arguments vvv\n",
    "network_parameters = [10,10]\n",
    "run_name = 'test'\n",
    "DEBUG_MODE = True\n",
    "# script below\n",
    "\n",
    "runs_folder = \"runs\"\n",
    "img_path = \"img\"\n",
    "run_path = \"\\\\\".join((runs_folder, run_name))\n",
    "    \n",
    "if not os.path.isdir(run_path):\n",
    "    raise ValueError(f\"The directory \\\"{\"\\\\\".join((runs_folder, run_name))}\\\", does not exist!\")\n",
    "    \n",
    "if not os.path.isdir(img_path):\n",
    "    raise ValueError(f\"The directory \\\"{img_path}\\\", does not exist!\")\n",
    "\n",
    "bin_folder = \"\\\\\".join((run_path,\"bin_files\")) # should include a file for expected outputs as a lits of output values for all layers concatenated\n",
    "mif_folder = \"\\\\\".join((run_path,\"mif_files\")) # hex files for simulation go here including expected values\n",
    "txt_folder = \"\\\\\".join((run_path,\"txt_files\")) # same as the above but in decimal representation\n",
    "folders = [bin_folder, mif_folder, txt_folder]\n",
    "\n",
    "INPUT_SIZE=784\n",
    "\n",
    "x32 = Fxp(-7.25, dtype='S5.27') # For now hardwired to 32/64 bits, but could be made to be generalizable\n",
    "x64 = Fxp(-7.25, dtype='S10.54')\n",
    "weights = []\n",
    "bias = []\n",
    "\n",
    "with open(os.path.join(img_path, f\"MNIST_train.bin\"), 'rb') as file:\n",
    "    data = file.read()\n",
    "    format_string = f'{60000*784}I'  # 'I' for unsigned int, repeat for num_elements\n",
    "    train_img = struct.unpack(format_string, data)\n",
    "    train_img = np.array(train_img).reshape(60000,784) # formatting image data\n",
    "    \n",
    "with open(os.path.join(img_path, f\"MNIST_test.bin\"), 'rb') as file:\n",
    "    data = file.read()\n",
    "    format_string = f'{10000*784}I'  # 'I' for unsigned int, repeat for num_elements\n",
    "    test_img = struct.unpack(format_string, data)\n",
    "    test_img = np.array(test_img).reshape(10000,784) # formatting image data\n",
    "\n",
    "\n",
    "# Reading weights and biases from files for each layer\n",
    "for layer in range(len(network_parameters)):\n",
    "    input_size_for_layer = INPUT_SIZE if layer == 0 else network_parameters[layer - 1]\n",
    "    \n",
    "    # Initialize weights and bias for the current layer\n",
    "    weights_layer = np.zeros((input_size_for_layer, network_parameters[layer]),dtype=( np.str_, 10)) #\n",
    "    bias_layer = np.zeros(network_parameters[layer],dtype=( np.str_, 10))\n",
    "    \n",
    "    # Read biases in hexfor the current layer\n",
    "    with open(os.path.join(mif_folder, f\"bias_{layer}.mif\"), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(network_parameters[layer]):\n",
    "            bias_layer[i] = lines[i].strip()\n",
    "    bias.append(bias_layer)\n",
    "\n",
    "    # Read weights for the current layer\n",
    "    for neuron in range(network_parameters[layer]):\n",
    "        with open(os.path.join(mif_folder, f\"weight_{layer}_{neuron}.mif\"), \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for i in range(input_size_for_layer):\n",
    "                weights_layer[i, neuron] = lines[i].strip()\n",
    "                \n",
    "    weights.append(weights_layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1bc31fb-73b5-4d8c-a718-6b6e1e343fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7529a412-92d5-4050-9369-cfcd343830e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb07569-37b4-4992-a3ad-eef55105eb3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7125ea-ab59-4a2c-b1f0-4471586fe69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111011110001101010011011000000101011001001000000010011001110001\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "OVERFLOW",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m  \u001b[38;5;28mabs\u001b[39m(val1 \u001b[38;5;241m-\u001b[39m acc_float) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0000001\u001b[39m: \u001b[38;5;66;03m# This verifies that the fixed point calculation agrees with the floating point calculation within 7 decimal places...\u001b[39;00m\n\u001b[0;32m     46\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ACCUMULATE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_float\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, are not equal at layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, neuron \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and input value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m     layer_output\u001b[38;5;241m.\u001b[39mappend(convert64_32(acc))\n\u001b[0;32m     50\u001b[0m     layer_output_float\u001b[38;5;241m.\u001b[39mappend(acc_float)\n\u001b[0;32m     52\u001b[0m a_tdata\u001b[38;5;241m.\u001b[39mappend(layer_output)\n",
      "Cell \u001b[1;32mIn[13], line 103\u001b[0m, in \u001b[0;36mconvert64_32\u001b[1;34m(bin_str1)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bin_str1[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1111\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mprint\u001b[39m(bin_str1)\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOVERFLOW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     bin_str2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m\n",
      "\u001b[1;31mException\u001b[0m: OVERFLOW"
     ]
    }
   ],
   "source": [
    "# Feedforward fixed-point calculation for each layer\n",
    "a_tdata = []\n",
    "a_tdata_float = []\n",
    "for layer in range(len(network_parameters)):\n",
    "    input_size_for_layer = INPUT_SIZE if layer == 0 else network_parameters[layer - 1]\n",
    "    input_data = img if layer == 0 else a_tdata[layer - 1]\n",
    "    layer_output = []\n",
    "    layer_output_float = []\n",
    "    for j in range(network_parameters[layer]):\n",
    "        b = bias[layer][j]\n",
    "        acc = convert32_64(x32(b).bin())\n",
    "        \n",
    "        b_float = float(x32(bias[layer][j]))\n",
    "        acc_float = b_float\n",
    "\n",
    "        if  float(x32(b)) != b_float:\n",
    "            raise Exception(f\"BIAS %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", float(x32(b)), b_float)\n",
    "        \n",
    "        for i in range(input_size_for_layer):\n",
    "            w, x = x32(weights[layer][i, j]).bin(), x32(input_data[i]).bin()\n",
    "            p = manual_binary_multiply(w, x)\n",
    "            # if add_binary(acc,p) == 'fail': \n",
    "            #     raise Except(f\"ERROR OVERFLOW at {layer, j, i}\")\n",
    "            acc = add_binary(acc, p)\n",
    "\n",
    "            if len(x32(input_data[i]).bin()) != 32:\n",
    "                print(i)\n",
    "                print(input_data[i])\n",
    "                \n",
    "            w_float, x_float = float(x32(weights[layer][i, j])), float(x32(input_data[i]))\n",
    "            p_float = w_float * x_float\n",
    "            acc_float = acc_float + p_float\n",
    "\n",
    "            print(val1, end='\\n')\n",
    "\n",
    "            val1 = float(x64('0b'+acc))\n",
    "            val2 = float(x32('0b'+w))\n",
    "            val3 = float(x32('0b'+x))\n",
    "            val4 = float(x64('0b'+p))\n",
    "            \n",
    "            if  val2 != w_float:\n",
    "                raise Exception(f\"WEIGHTS {val2}, {w_float}, are not equal at layer {layer}, neuron {j} and input value {i}\")\n",
    "            if  val3 != x_float:\n",
    "                raise Exception(f\"img {val3}, {x_float}, are not equal at layer {layer}, neuron {j} and input value {i}\")\n",
    "            if  val4 != p_float:\n",
    "                raise Exception(f\"SUM {val4}, {p_float}, are not equal at layer {layer}, neuron {j} and input value {i}\")\n",
    "            if  abs(val1 - acc_float) > 0.0000001: # This verifies that the fixed point calculation agrees with the floating point calculation within 7 decimal places...\n",
    "                raise Exception(f\" ACCUMULATE {val1}, {acc_float}, are not equal at layer {layer}, neuron {j} and input value {i}\")\n",
    "            \n",
    "        layer_output.append(convert64_32(acc))\n",
    "        \n",
    "        layer_output_float.append(acc_float)\n",
    "    \n",
    "    a_tdata.append(layer_output)\n",
    "    \n",
    "    a_tdata_float.append(layer_output_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43ec25d-7479-42c7-8dde-f7009c5f05c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(fxp-s64/54(-33.792144453967374), 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x64('0b1111011110001101010011011000000101011001001000000010011001110001'), 2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "543d7069-7c42-42b1-a785-17b006961ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1111111111100100101011111001110000111000000000000000000000000000'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a204fc53-2ebe-431e-91e4-628ebbb2852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1111111000110000000000000000000000000000000000000000000000000000'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x64 = Fxp(-7.25, dtype='S10.54')\n",
    "x64.bin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14c78577-cc4c-4e5d-a56c-caee7aae6bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fxp-s64/54(-0.426781602203846)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x64('0b'+acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de58a27b-a884-4e0b-9c89-4a1e98a84c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fxp-s64/54(512.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x64(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04f9af28-e386-4967-9696-f51c3f353203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fxp-s32/27(15.99999999254942)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x32('00000000011111101000011111000100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c09bf15c-725a-427d-94b1-a0b238459615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fxp-s32/27(0.061782389879226685)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x32(weights[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c683639-5588-4a4c-a859-7997214400aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00000000011111101000011111000100'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x32(weights[0][0][0]).bin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "637b14a0-1e59-433c-be74-354f24b09d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6462b028-98ae-40a4-bc12-3e581cc9bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0xFC95F387\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bin_folder = \"\\\\\".join((run_path,\"bin_files\")) # should include a file for expected outputs as a lits of output values for all layers concatenated\n",
    "mif_folder = \"\\\\\".join((run_path,\"mif_files\")) # hex files for simulation go here including expected values\n",
    "txt_folder = \"\\\\\".join((run_path,\"txt_files\")) # same as the above but in decimal representation\n",
    "folders = [bin_folder, mif_folder, txt_folder]\n",
    "\n",
    "with open(os.path.join(mif_folder, f\"bias_{layer}.mif\"), \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    print(lines[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a51b8b66-bffd-42ce-9625-667e3350e484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0xFC95F387']], dtype='<U10')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug =  np.zeros((1, 1),dtype=( np.str_, 10))\n",
    "debug[0]='FFAAFFAA'\n",
    "debug[0] = lines[0].strip()\n",
    "debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2397321c-7135-4207-92d0-abf234a82a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(img_path, f\"MNIST_train.bin\"), 'rb') as file:\n",
    "    IMG_SET_BINARY = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7510ed52-51a9-411a-9bab-c0942e8e6255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188160000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IMG_SET_BINARY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5f6d59b-c8e9-4632-9a02-371ed7156371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SET_BINARY[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d708fb-9749-4265-a1d3-09c8f3d8e395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376320000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IMG_SET_BINARY.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fba73f6-07fd-42c8-b9bf-794e39b0ca19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "376320000/(60000*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8f9f6cb-3dba-471e-8a29-8d67ef11972e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "188160000/(60000*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05416622-d4c5-412e-a66b-bdeabaa0813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x32 = Fxp(-7.25, dtype='S5.27') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fcc0f37-6f90-434e-bcec-9799ec40f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_binary_file(filename, num_elements):\n",
    "    with open(filename, 'rb') as file:\n",
    "        # Calculate the number of bytes to read (4 bytes per uint32)\n",
    "        data = file.read(num_elements * 4)\n",
    "        \n",
    "        # Unpack the binary data as uint32 (32-bit unsigned integers)\n",
    "        format_string = f'{num_elements}I'  # 'I' for unsigned int, repeat for num_elements\n",
    "        values = struct.unpack(format_string, data)\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a35f0aa0-de17-46d7-b9ee-125c45187adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(img_path, f\"MNIST_train.bin\")\n",
    "num_elements = 60000 * 784  # Total number of uint32 values\n",
    "\n",
    "# Load the binary data\n",
    "img_data = load_binary_file(filename, num_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51d6bedc-5ef5-41b8-9ec0-b63b950b69d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
       "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
       "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
       "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
       "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
       "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
       "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
       "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_data = np.array(img_data).reshape(60000,784)\n",
    "img_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098312a3-69f5-40ab-8ad4-fb0ca54f8500",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60000):\n",
    "    for j in range(784):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
