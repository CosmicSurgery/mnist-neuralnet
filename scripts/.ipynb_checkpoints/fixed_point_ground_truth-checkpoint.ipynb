{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e44feb-0207-43f3-9d93-cd0d8eaaee33",
   "metadata": {},
   "source": [
    "# This script runs a prototype feed-forward prototype of the neural network that will be run on a zybo fpga. The script will produce a c-compatible file with values representations stored in (hex??). \n",
    "\n",
    "### Todo\n",
    "- [ ] convert decimal to binary.\n",
    "- [ ] create a binary multiplier function (optimal?)\n",
    "- [ ] choose a prototype architecture and store relevant results in a certain format.\n",
    "- [ ] Decide how software/hardware fixed-point results will be compared to verify correct implementation on hardware? Do i need to do it in C on the Zynq?\n",
    "\n",
    "### Outstanding Questions\n",
    "\n",
    "- How should I implement the multiplier in python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd121146-37cf-47b0-b541-39d84adf7e8d",
   "metadata": {},
   "source": [
    "## How to choose an architecture?\n",
    "my bit representation is S4.27 -> meaning I have a two's complement sign bit, 4 integer bits and 27 fractional bits.\n",
    "\n",
    "What does this mean?\n",
    "- fractional resolution is: 0.00000000372529029846\n",
    "    - I can represent 7 fractional digits accurately?\n",
    "Biggest magnitude number I can represent is +/- (16 - 0.00000000372529029846) Right?\n",
    "This is probably overkill. Would be worthwhile looking at reviews of fixed point precision compared to various metrics.\n",
    "\n",
    "I will stick with this convention for this milestone, but can try different conventions for future milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45122136-5c57-43f7-b98e-04bcd606632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in os.listdir(os.path.join(os.getcwd(),\"bin_files\")):\n",
    "    # print(entry)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b6f67aa-0d7f-4293-a26c-e0265dfddcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fxpmath import Fxp\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f751f4a5-c903-48a8-850b-faa705aac374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000001101111000101110100111011011010111000011001011110001110', '1111111111000101100010011010011111001001111011010101110000101001', '0000000000111100111110101111111010100101111000110101010111100010']\n",
      "['1111111111001101111101100011000001001011111001111110011111011000']\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "%run plnn_validation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83a7241e-be83-4da7-aae5-4c58abd6a206",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/git_repos/mnist_neuralnet/scripts/MNIST_single_test_img1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\git_repos\\mnist_neuralnet\\scripts\\create_img_h_file.py:9\u001b[0m\n\u001b[0;32m      4\u001b[0m sample_img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMNIST_single_test_img1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m data_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDEBUGtest_img_data2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 9\u001b[0m f_read \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((directory_path, sample_img_path)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m img_str \u001b[38;5;241m=\u001b[39m f_read\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m f_read\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/git_repos/mnist_neuralnet/scripts/MNIST_single_test_img1.txt'"
     ]
    }
   ],
   "source": [
    "%run create_img_h_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb46288-42c4-4ed9-ad56-55b0843d210d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce71405-d7b2-4210-8ab9-625a2c6293a5",
   "metadata": {},
   "source": [
    "# Workbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27e281dd-9bf8-47d6-af43-05b6469e1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fxpmath import Fxp\n",
    "import sys\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9603780-257c-4aa4-8bae-3c4269024944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00001101000101111000101000111110111001000101111101\n"
     ]
    }
   ],
   "source": [
    "# Thank you Chatgpt!!!\n",
    "def twos_complement(bin_str):\n",
    "    \"\"\"Returns the two's complement of a binary string.\"\"\"\n",
    "    # Invert the bits\n",
    "    inverted = ''.join('1' if bit == '0' else '0' for bit in bin_str)\n",
    "    # Add 1 to the inverted binary string\n",
    "    carry = 1\n",
    "    result = list(inverted)\n",
    "    \n",
    "    for i in range(len(inverted) - 1, -1, -1):\n",
    "        if result[i] == '1' and carry == 1:\n",
    "            result[i] = '0'\n",
    "        elif result[i] == '0' and carry == 1:\n",
    "            result[i] = '1'\n",
    "            carry = 0\n",
    "        # No carry to add; break early\n",
    "        if carry == 0:\n",
    "            break\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "def add_binary(bin_str1, bin_str2):\n",
    "    \"\"\"Adds two binary strings and returns the result as a binary string, \n",
    "    handling overflow by setting the result to the max/min value depending on overflow direction.\"\"\"\n",
    "    max_len = max(len(bin_str1), len(bin_str2))\n",
    "    bin_str1 = bin_str1.zfill(max_len)\n",
    "    bin_str2 = bin_str2.zfill(max_len)\n",
    "    \n",
    "    carry = 0\n",
    "    result = []\n",
    "    \n",
    "    # Perform bitwise addition from LSB to MSB\n",
    "    for i in range(max_len - 1, -1, -1):\n",
    "        bit_sum = carry + int(bin_str1[i]) + int(bin_str2[i])\n",
    "        result.append(str(bit_sum % 2))\n",
    "        carry = bit_sum // 2\n",
    "    \n",
    "    result = ''.join(result[::-1])  # Reverse the result to get the correct order\n",
    "    \n",
    "    # Check for overflow\n",
    "    sign1 = bin_str1[0]  # Sign bit of the first number\n",
    "    sign2 = bin_str2[0]  # Sign bit of the second number\n",
    "    result_sign = result[0]  # Sign bit of the result\n",
    "\n",
    "    # Overflow occurs if both numbers have the same sign but the result has a different sign\n",
    "    if sign1 == sign2 and sign1 != result_sign:\n",
    "        if sign1 == '0':  # Positive overflow\n",
    "            result = '0' + '1' * (max_len - 1)  # Max positive value: 011...111\n",
    "        else:  # Negative overflow\n",
    "            result = '1' + '0' * (max_len - 1)  # Max negative value: 100...000\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def manual_binary_multiply(bin_str1, bin_str2):\n",
    "    \"\"\"Multiplies two binary strings in two's complement format manually.\"\"\"\n",
    "    # Check for sign and convert to positive if necessary\n",
    "    is_negative1 = bin_str1[0] == '1'\n",
    "    is_negative2 = bin_str2[0] == '1'\n",
    "    \n",
    "    if is_negative1:\n",
    "        bin_str1 = twos_complement(bin_str1)\n",
    "    if is_negative2:\n",
    "        bin_str2 = twos_complement(bin_str2)\n",
    "\n",
    "    # Perform binary multiplication (manual)\n",
    "    len1 = len(bin_str1)\n",
    "    len2 = len(bin_str2)\n",
    "    result = '0' * (len1 + len2)\n",
    "    \n",
    "    for i in range(len2 - 1, -1, -1):\n",
    "        if bin_str2[i] == '1':\n",
    "            # Shift bin_str1 by (len2 - 1 - i) and add to the result\n",
    "            shifted_bin_str1 = bin_str1 + '0' * (len2 - 1 - i)\n",
    "            result = add_binary(result, shifted_bin_str1.zfill(len1 + len2))\n",
    "    \n",
    "    # Determine the sign of the result\n",
    "    if is_negative1 != is_negative2:\n",
    "        result = twos_complement(result.zfill(len1 + len2))\n",
    "\n",
    "    # Truncate the result to the appropriate length (len1 + len2 bits)\n",
    "    return result[-(len1 + len2):]\n",
    "\n",
    "# Example usage:\n",
    "bin_str1 = \"1101101011010100010110101\"  # -3 in 4-bit two's complement\n",
    "bin_str2 = \"1010010111010101010101001\"  # -6 in 4-bit two's complement\n",
    "\n",
    "result = manual_binary_multiply(bin_str1, bin_str2)\n",
    "print(result)  # 8-bit result in two's complement binary format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cdc3b59d-9ed8-40e9-a82a-8cd7032deb3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0000000100011110111010010100011010010101110011000101001100000100', '0000000010110001101111010011001010000010111111001111010101000000', '0000000000000000111011001010001000001110100100001100010111110101']\n",
      "[4.482988020217181, 2.777172687452387, 0.014442934250018635]\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the folder for the binary files\n",
    "hex_folder = \"hex_files\"\n",
    "txt_folder = \"txt_files\"\n",
    "bin_folder = \"bin_files\"\n",
    "h_folder = \"header_files\"\n",
    "folders = [hex_folder, txt_folder, bin_folder, h_folder]\n",
    "\n",
    "x32 = Fxp(-7.25, dtype='S5.27')\n",
    "x64 = Fxp(-7.25, dtype='S10.54')\n",
    "num_layers = 1  # Example: 2 layers\n",
    "neurons_per_layer = [3]  # Example: 3 neurons in layer 1, 2 neurons in layer 2\n",
    "input_size = 784\n",
    "weights = []\n",
    "bias = []\n",
    "img = [0 for k in range(input_size)]\n",
    "if gen_output_files:\n",
    "    for folder in folders:\n",
    "        # Create the folder if it doesn't exist\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        files = glob.glob(os.path.join(folder, \"*\"))\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(f)  # Remove each file\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting file {f}: {e}\")\n",
    "    img = (np.random.rand(1,input_size) * 2) -1\n",
    "\n",
    "    with open(os.path.join(txt_folder, \"img.txt\"), \"w\") as file:\n",
    "        for i in range(input_size):\n",
    "            file.write(str(float(x32(img[0,i])))+\"\\n\")\n",
    "    with open(os.path.join(bin_folder, \"img.mif\"), \"w\") as file:\n",
    "        for i in range(input_size):\n",
    "            file.write(str(x32(img[0,i]).bin())+\"\\n\")\n",
    "    with open(os.path.join(hex_folder, \"img.mif\"), \"w\") as file:\n",
    "        for i in range(input_size):\n",
    "            file.write(str(x32(img[0,i]).hex())+\"\\n\")\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        \n",
    "        input_size_for_layer = input_size if layer == 0 else neurons_per_layer[layer - 1]\n",
    "        weights.append((np.random.rand(input_size_for_layer, neurons_per_layer[layer]) * 2) - 1)\n",
    "        bias.append((np.random.rand(neurons_per_layer[layer]) * 2) - 1)\n",
    "        \n",
    "        with open(os.path.join(txt_folder, f\"bias_{layer}.txt\"), \"w\") as file:\n",
    "            for i in range(neurons_per_layer[layer]):\n",
    "                file.write(str(float(x32(bias[layer][i]))) + \"\\n\")\n",
    "        with open(os.path.join(bin_folder, f\"bias_{layer}.mif\"), \"w\") as file:\n",
    "            for i in range(neurons_per_layer[layer]):\n",
    "                file.write(str(x32(bias[layer][i]).bin()) + \"\\n\")\n",
    "        with open(os.path.join(hex_folder, f\"bias_{layer}.mif\"), \"w\") as file:\n",
    "            for i in range(neurons_per_layer[layer]):\n",
    "                file.write(str(x32(bias[layer][i]).hex()) + \"\\n\")\n",
    "                \n",
    "        for neuron in range(neurons_per_layer[layer]):\n",
    "                \n",
    "            with open(os.path.join(txt_folder, f\"weight_{layer}_{neuron}.txt\"), \"w\") as file:\n",
    "                for i in range(input_size_for_layer):\n",
    "                    file.write(str(float(x32(weights[layer][i, neuron]))) + \"\\n\")\n",
    "            with open(os.path.join(bin_folder, f\"weight_{layer}_{neuron}.mif\"), \"w\") as file:\n",
    "                for i in range(input_size_for_layer):\n",
    "                    file.write(str(x32(weights[layer][i, neuron]).bin()) + \"\\n\")\n",
    "            with open(os.path.join(hex_folder, f\"weight_{layer}_{neuron}.mif\"), \"w\") as file:\n",
    "                for i in range(input_size_for_layer):\n",
    "                    file.write(str(x32(weights[layer][i, neuron]).hex()) + \"\\n\")\n",
    "\n",
    "    with open(os.path.join(h_folder, \"img.h\"), \"w\") as file:\n",
    "        file.write(\"#ifndef IMG_H\\n\")\n",
    "        file.write(\"#define IMG_H\\n\\n\")\n",
    "        \n",
    "        file.write(\"unsigned char bin_img[784] = { \")\n",
    "        for i in range(input_size):\n",
    "            # Convert the value to an unsigned char representation (assuming the range is normalized between -1 and 1)\n",
    "            file.write( '0b'+str(x32(img[0,i]).bin())+\", \" if i < input_size -1 else '0b'+str(x32(img[0,i]).bin()) )\n",
    "        file.write(\" };\\n\\n\")\n",
    "\n",
    "        file.write(\"unsigned char hex_img[784] = { \")\n",
    "        for i in range(input_size):\n",
    "            # Convert the value to an unsigned char representation (assuming the range is normalized between -1 and 1)\n",
    "            file.write( str(x32(img[0,i]).hex())+\", \" if i < input_size -1 else str(x32(img[0,i]).hex()) )\n",
    "        file.write(\" };\\n\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "        file.write(\"#endif // IMG_H\\n\")\n",
    "weights = []\n",
    "bias = []\n",
    "img = [0 for k in range(input_size)]\n",
    "# Read img for the current layer\n",
    "with open(os.path.join(bin_folder, f\"img.mif\"), \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(input_size):\n",
    "        img[i] = lines[i].strip()\n",
    "\n",
    "# Reading weights and biases from files for each layer\n",
    "for layer in range(num_layers):\n",
    "    input_size_for_layer = input_size if layer == 0 else neurons_per_layer[layer - 1]\n",
    "    \n",
    "    # Initialize weights and bias for the current layer\n",
    "    weights_layer = np.zeros((input_size_for_layer, neurons_per_layer[layer]),dtype=( np.str_, 32))\n",
    "    bias_layer = np.zeros(neurons_per_layer[layer],dtype=( np.str_, 32))\n",
    "    \n",
    "    # Read biases for the current layer\n",
    "    with open(os.path.join(bin_folder, f\"bias_{layer}.mif\"), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "        for i in range(neurons_per_layer[layer]):\n",
    "            bias_layer[i] = lines[i].strip()\n",
    "    bias.append(bias_layer)\n",
    "\n",
    "    # Read weights for the current layer\n",
    "    for neuron in range(neurons_per_layer[layer]):\n",
    "        with open(os.path.join(bin_folder, f\"weight_{layer}_{neuron}.mif\"), \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for i in range(input_size_for_layer):\n",
    "                weights_layer[i, neuron] = lines[i].strip()\n",
    "                \n",
    "    weights.append(weights_layer)\n",
    "\n",
    "# Feedforward fixed-point calculation for each layer\n",
    "a_tdata = []\n",
    "a_tdata_float = []\n",
    "for layer in range(num_layers):\n",
    "    input_data = img if layer == 0 else a_tdata[layer - 1]\n",
    "    layer_output = []\n",
    "    layer_output_float = []\n",
    "    for j in range(neurons_per_layer[layer]):\n",
    "        b = bias[layer][j]\n",
    "        \n",
    "        acc = ['0']*64\n",
    "        acc[5:len(b)+5] = b\n",
    "        acc = ''.join(acc)\n",
    "        \n",
    "        b_float = float(x32(''.join(('0b',bias[layer][j]))))\n",
    "        acc_float = b_float\n",
    "\n",
    "        if  float(x32(''.join(('0b',b)))) != b_float:\n",
    "            raise Exception(f\"BIAS %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", float(x64(''.join(('0b',b)))), b_float)\n",
    "        \n",
    "        for i in range(input_size_for_layer):\n",
    "            w = weights[layer][i,j]\n",
    "            w, x = weights[layer][i, j], input_data[i]\n",
    "            p = manual_binary_multiply(w, x)\n",
    "            acc = add_binary(acc, p)\n",
    "            \n",
    "            w_float, x_float = float(x32(''.join(('0b',weights[layer][i, j])))), float(x32(''.join(('0b',input_data[i]))))\n",
    "            p_float = w_float * x_float\n",
    "            acc_float = acc_float + p_float\n",
    "\n",
    "            val1 = float(x64(''.join(('0b',acc))))\n",
    "            val2 = float(x32(''.join(('0b',w))))\n",
    "            val3 = float(x32(''.join(('0b',x))))\n",
    "            val4 = float(x64(''.join(('0b',p))))\n",
    "            \n",
    "            if  val2 != w_float:\n",
    "                raise Exception(f\"WEIGHTS %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", val2, w_float)\n",
    "            if  val3 != x_float:\n",
    "                raise Exception(f\"img %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", val3, x_float)\n",
    "            if  val4 != p_float:\n",
    "                raise Exception(f\"SUM %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", val4, p_float)\n",
    "            if  abs(val1 - acc_float) > 0.0000001: # This verifies that the fixed point calculation agrees with the floating point calculation within 7 decimal places...\n",
    "                raise Exception(f\" ACCUMULATE %s, %d, are not equal at layer {layer}, neuron {j} and input value {i}\", val1, acc_float)\n",
    "            \n",
    "        layer_output.append(acc)\n",
    "        \n",
    "        layer_output_float.append(acc_float)\n",
    "    \n",
    "    a_tdata.append(layer_output)\n",
    "    \n",
    "    a_tdata_float.append(layer_output_float)\n",
    "    \n",
    "    with open(os.path.join(bin_folder, f\"output_layer_{layer}.mif\"), \"w\") as file:\n",
    "        for i in range(neurons_per_layer[layer]):\n",
    "            file.write(layer_output[i] + \"\\n\")\n",
    "    with open(os.path.join(hex_folder, f\"output_layer_{layer}.mif\"), \"w\") as file:\n",
    "        for i in range(neurons_per_layer[layer]):\n",
    "            file.write(x64(''.join(('0b',layer_output[i]))).hex() + \"\\n\")\n",
    "     \n",
    "    with open(os.path.join(txt_folder, f\"output_layer_{layer}.txt\"), \"w\") as file:\n",
    "        for i in range(neurons_per_layer[layer]):\n",
    "            file.write(str(layer_output_float[i]) + \"\\n\")\n",
    "            \n",
    "for layer in range(num_layers):\n",
    "    print(a_tdata[layer], end='\\n')\n",
    "    \n",
    "    print(a_tdata_float[layer], end='\\n')\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc74f51-7aa5-450d-bdfe-30cd074b216d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "026ade64-5b63-43b2-8522-25f96b22420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000100001011010101000111010000010000001111101110110101010101',\n",
       " '0000000010101111110101110100101011100011001110011011001000110100',\n",
       " '1111111111011101100000011011011110011010111111100010001101000100']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "64b3bdc6-f91d-44a1-a4ce-3e14186ebd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.482988020217181, 2.777172687452387, 0.014442934250018635]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9e09ed01-56e6-4635-b630-f1d665d927e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11111000001010001101100110011001', '11111100011111110110111110101000')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0][0,0], img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b812c0-b709-462e-a2f5-1dcafd657a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "61a213d2-2826-431a-831d-437e64837d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00013020634651184082"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(x32('0b0100010001000100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5d829b2e-86e5-4e37-bd01-300a02f4637d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_output_files=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b46d8e-18ea-4836-b3cd-abbfb44fdb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3062a-f5bb-4187-a13d-9776e3a69e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
