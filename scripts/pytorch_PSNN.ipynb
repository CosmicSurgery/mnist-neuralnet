{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8681f488-e79b-454c-acc2-e83f791b7d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2763bd-e1b1-4821-93a8-eac32b899c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4271ef60-f0ea-4f67-b80e-8161e856cc83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "bs = 1\n",
    "epochs = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1151e913-2145-4afc-ba93-bfeee7a969f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "        \n",
    "def get_model():\n",
    "    model = NeuralNetwork()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    return model, loss_fn, optimizer\n",
    "\n",
    "def get_data(training_data, test_data, bs):\n",
    "    return (\n",
    "        DataLoader(training_data, batch_size=bs), #, shuffle=True),\n",
    "        DataLoader(test_data, batch_size=bs),\n",
    "    )\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    correct = 0\n",
    "    size = len(train_dl.dataset)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch, (xb, yb) in enumerate(train_dl):\n",
    "            # xb = xb.to(device), yb.to(device)\n",
    "            loss, _ = loss_batch(model, loss_func, xb, yb, opt)\n",
    "            correct += bool(model(xb).argmax() == yb)\n",
    "            \n",
    "            if batch % 100 == 0:\n",
    "                current = (batch + 1) * len(xb)\n",
    "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        \n",
    "\n",
    "        correct /= len(train_dl.dataset)\n",
    "\n",
    "        print(f\"Training Error: \\n Accuracy: {(100*correct):>0.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40075769-4896-4b8d-a0aa-20bb86aa1b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "train_dl, valid_dl = get_data(training_data, test_data, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04026ee1-e6a8-4ae4-8290-04f619c6bb56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.399653  [    1/60000]\n",
      "loss: 2.330267  [ 1001/60000]\n",
      "loss: 2.712936  [ 2001/60000]\n",
      "loss: 2.357742  [ 3001/60000]\n",
      "loss: 1.477537  [ 4001/60000]\n",
      "loss: 1.230931  [ 5001/60000]\n",
      "loss: 0.831079  [ 6001/60000]\n",
      "loss: 1.956707  [ 7001/60000]\n",
      "loss: 0.114509  [ 8001/60000]\n",
      "loss: 0.734352  [ 9001/60000]\n",
      "loss: 0.196807  [10001/60000]\n",
      "loss: 0.086218  [11001/60000]\n",
      "loss: 0.363267  [12001/60000]\n",
      "loss: 0.556539  [13001/60000]\n",
      "loss: 0.114997  [14001/60000]\n",
      "loss: 0.867073  [15001/60000]\n",
      "loss: 0.062347  [16001/60000]\n",
      "loss: 0.333005  [17001/60000]\n",
      "loss: 0.211893  [18001/60000]\n",
      "loss: 0.513849  [19001/60000]\n",
      "loss: 0.008754  [20001/60000]\n",
      "loss: 0.783907  [21001/60000]\n",
      "loss: 0.189741  [22001/60000]\n",
      "loss: 0.011704  [23001/60000]\n",
      "loss: 0.214129  [24001/60000]\n",
      "loss: 1.446226  [25001/60000]\n",
      "loss: 0.262589  [26001/60000]\n",
      "loss: 0.837122  [27001/60000]\n",
      "loss: 0.044474  [28001/60000]\n",
      "loss: 0.127537  [29001/60000]\n",
      "loss: 0.009463  [30001/60000]\n",
      "loss: 1.633116  [31001/60000]\n",
      "loss: 0.118802  [32001/60000]\n",
      "loss: 1.219688  [33001/60000]\n",
      "loss: 0.354783  [34001/60000]\n",
      "loss: 0.012834  [35001/60000]\n",
      "loss: 0.871888  [36001/60000]\n",
      "loss: 0.046133  [37001/60000]\n",
      "loss: 0.169913  [38001/60000]\n",
      "loss: 0.914265  [39001/60000]\n",
      "loss: 0.003150  [40001/60000]\n",
      "loss: 0.108965  [41001/60000]\n",
      "loss: 0.012286  [42001/60000]\n",
      "loss: 0.540199  [43001/60000]\n",
      "loss: 0.012869  [44001/60000]\n",
      "loss: 0.250599  [45001/60000]\n",
      "loss: 0.247943  [46001/60000]\n",
      "loss: 0.030667  [47001/60000]\n",
      "loss: 0.111910  [48001/60000]\n",
      "loss: 0.049927  [49001/60000]\n",
      "loss: 0.182200  [50001/60000]\n",
      "loss: 0.019004  [51001/60000]\n",
      "loss: 0.111335  [52001/60000]\n",
      "loss: 0.025411  [53001/60000]\n",
      "loss: 1.068782  [54001/60000]\n",
      "loss: 0.038125  [55001/60000]\n",
      "loss: 0.018709  [56001/60000]\n",
      "loss: 0.000066  [57001/60000]\n",
      "loss: 0.281889  [58001/60000]\n",
      "loss: 0.012057  [59001/60000]\n",
      "Training Error: \n",
      " Accuracy: 84.9%\n",
      "57.020005226135254\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "train_dl, valid_dl = get_data(training_data, test_data, bs)\n",
    "model, loss_func, opt = get_model()\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "start_time = time.time()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n",
    "stop_time = time.time()\n",
    "print(stop_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "905f6503-ac2d-4447-8cf8-eecd9f63a347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6209, -6.4523,  0.8480,  3.7399, -2.7591, -0.7681, -7.3642, 10.1244,\n",
       "          0.2005,  4.4697],\n",
       "        [ 6.9891, -0.9531,  9.2795,  5.8925, -9.3502,  5.8432,  6.4225, -9.6935,\n",
       "          5.3983, -5.3377]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "803aeb0c-102a-4caa-b716-8017a4189658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a1032554-6291-45d5-9cac-a04458388f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug = iter(valid_dl)\n",
    "next(debug)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf51fb1c-1f0e-488c-94a1-914a9ef1cd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 10.9\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m             correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     11\u001b[0m     stop_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 12\u001b[0m     times[i] \u001b[38;5;241m=\u001b[39m stop_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(times\u001b[38;5;241m.\u001b[39mmean())\n",
      "\u001b[1;31mIndexError\u001b[0m: index 10 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "start_time = time.time()\n",
    "times = np.zeros(10)\n",
    "for i in range(10):\n",
    "    for batch, (xb, yb) in enumerate(valid_dl):\n",
    "        pred = model(xb).argmax()\n",
    "        if batch % 1000 == 0:\n",
    "            print(f\"Complete: {batch/len(valid_dl)+i}\", end=\"\\r\")\n",
    "        if pred == yb:\n",
    "            correct +=1\n",
    "    stop_time = time.time()\n",
    "    times[i] = stop_time - start_time\n",
    "print(np.diff(times).mean())\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "57d767d4-31d9-4ec7-a3b8-d4928f6cb20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7625641557905407"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(times).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ca23c-8ab6-4292-a4c5-92fb540f947e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
